{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hedgehog-zowie/tf-study/blob/master/fashion_mnist_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "z8rEYifvBUHQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "第一个tensorflow例子，使用tensorflow的keras api实现服饰图像分类。"
      ]
    },
    {
      "metadata": {
        "id": "v9XN8HdJC_HV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. 导入相关module。"
      ]
    },
    {
      "metadata": {
        "id": "DKuiaf4qBX0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "35c41676-2036-43c8-a9c7-012b9275f35a"
      },
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 查看各个module的版本\n",
        "print('tensorflow version: ', tf.__version__)\n",
        "print('numpy version: ', np.__version__)\n",
        "print('matplot version: ', mpl.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version:  1.13.0-rc1\n",
            "numpy version:  1.14.6\n",
            "matplot version:  3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7IpVOFpQDEBV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "OCGVBZJgDGiN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. 导入fashion mnist数据集。keras已经封装了一些数据集，包括mnist、fashion mnist、boston housing price等，我们可以非常简便地导入这些数据集。"
      ]
    },
    {
      "metadata": {
        "id": "imK7pVaSEBus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "# train_images和train_labels是训练集，test_images和test_labels是测试集\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L4UAYs6LEBAE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "4jbEbddqEoh9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. 对数据进行预处理，本例中仅需要将各个像素值缩放到0-1之间即可。"
      ]
    },
    {
      "metadata": {
        "id": "TevL8f64E2pU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RasbSR_dFHkm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "4. 设置层，包括层数，各层的神经元个数、激活函数等。"
      ]
    },
    {
      "metadata": {
        "id": "4Vdegmg6Fbl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "334128da-536f-4ee0-955e-0a810c8b0b44"
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    # 将图像组成向量进行扁平化处理，即将28 X 28的二维数组转换成一维数组\n",
        "    keras.layers.Flatten(input_shape=(28,28)),\n",
        "    # 全连接层，包含128个神经元，激活函数为relu\n",
        "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "    # 全连接层，包含10个神经元，激活函数为softmax\n",
        "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GeEYxKNBIwq5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "5. 编译模型，需要设置3个重要参数优化器、损失函数、评估指标。"
      ]
    },
    {
      "metadata": {
        "id": "ut3SEMh1Jcpt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "             loss = 'sparse_categorical_crossentropy',\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2zhD9DGjJxQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "6. 训练模型，将数据传递到模型中进行拟合，该方法也有几个重要的参数：epochs次数、batch_size（批量大小）、validation_data（验证集，包括data和label），如：model.fit(data, labels, epochs = 10, batch_size = 100, validation_data = (val_data, val_labels))。"
      ]
    },
    {
      "metadata": {
        "id": "iqs9KynpKCHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "bf069bc9-884e-47dd-f06f-bacefd088d01"
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs = 10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.4932 - acc: 0.8263\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3717 - acc: 0.8654\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3346 - acc: 0.8783\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.3130 - acc: 0.8857\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2962 - acc: 0.8908\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2795 - acc: 0.8959\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2690 - acc: 0.9005\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2581 - acc: 0.9040\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2475 - acc: 0.9073\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2399 - acc: 0.9102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2968dd828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "2zliynjAKPmj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "7. 模型评估，使用测试集进行模型评估。"
      ]
    },
    {
      "metadata": {
        "id": "94gwp1MDKb_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2a675ac7-c8c0-414f-fd50-12e4d41d5117"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test loss: ', test_loss, ', test accuracy: ', test_acc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.3330 - acc: 0.8814\n",
            "test loss:  0.3330352456450462 , test accuracy:  0.8814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z5Hj92kPKxgD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "8. 模型推理（预测），keras仅支持批量推理，因此，当我们仅需要对一个图像进行推理时，也需要将其添加到列表中，再调用predict方法。"
      ]
    },
    {
      "metadata": {
        "id": "imsg1odlK4MV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4aa6379c-d788-4dcd-f644-f5001c5cb4f4"
      },
      "cell_type": "code",
      "source": [
        "# 对所有测试集进行推理\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "print('对第0个图像的预测结果：', predictions[0])\n",
        "# 第0个图片真实分类\n",
        "c0 = test_labels[0]\n",
        "# 预测第0个图片的分类\n",
        "p0 = np.argmax(predictions[0])\n",
        "print('真实：', c0, '，预测为： ', p0)\n",
        "\n",
        "# 对单个图像进行推理\n",
        "img = test_images[1]\n",
        "img = np.expand_dims(img, 0)\n",
        "print('img1 shape: ', img.shape)\n",
        "predictions_single = model.predict(img)\n",
        "print('对单个图像的预测结果：', predictions_single)\n",
        "# 第1个图片真实分类\n",
        "c1 = test_labels[1]\n",
        "# 预测第1个图片的分类\n",
        "p1 = np.argmax(predictions_single[0])\n",
        "print('真实：', c1, '，预测为： ', p1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "对第0个图像的预测结果： [5.8751971e-06 8.9779850e-10 3.2791101e-07 2.2144020e-09 1.5430076e-07\n",
            " 1.6064715e-03 3.4987147e-06 4.9497437e-02 4.3552836e-06 9.4888186e-01]\n",
            "真实： 9 ，预测为：  9\n",
            "img1 shape:  (1, 28, 28)\n",
            "对单个图像的预测结果： [[1.5563150e-05 8.6228882e-14 9.9874061e-01 3.1488077e-13 9.7834913e-04\n",
            "  1.4646622e-08 2.6544533e-04 4.6769672e-17 1.0056744e-10 2.4889370e-16]]\n",
            "真实： 2 ，预测为：  2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}